{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vs9inZlbf5B"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0oHNrnUKbf5D"
   },
   "source": [
    "# Lab 6.1: K-Means by the algorithm\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "- Replace the `___` with proper code to run the cells\n",
    "- Observe and understand the results\n",
    "- Answer the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GoomMlDSbf5F"
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZPjfEAhbf5M"
   },
   "outputs": [],
   "source": [
    "# Load the Iris dataset from sklearn\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z59Id09Jbf5S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "## Get some description about the data\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Iq_Nz0nbf5Y"
   },
   "outputs": [],
   "source": [
    "# Declare the columns names\n",
    "columns = 'Sepal_Length Sepal_Width Petal_Length Petal_Width'.split()\n",
    "\n",
    "# Load the dataset as a pandas data frame\n",
    "X = pd.DataFrame(iris.data, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vStgPMwFbf5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is a <class 'pandas.core.frame.DataFrame'>\n",
      "X has 150 rows and 4 columns\n",
      "Basic Statistics about X__________________________________________________\n",
      "       Sepal_Length  Sepal_Width  Petal_Length  Petal_Width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "\n",
      "Sample of X__________________________________________________\n",
      "   Sepal_Length  Sepal_Width  Petal_Length  Petal_Width\n",
      "0           5.1          3.5           1.4          0.2\n",
      "1           4.9          3.0           1.4          0.2\n",
      "2           4.7          3.2           1.3          0.2\n",
      "3           4.6          3.1           1.5          0.2\n",
      "4           5.0          3.6           1.4          0.2\n"
     ]
    }
   ],
   "source": [
    "## Check data\n",
    "print('X is a %s' % type(X))\n",
    "print('X has %d rows and %d columns' % X.shape)\n",
    "print('Basic Statistics about X%s' % ('_'*50))\n",
    "print(X.describe())\n",
    "print('')\n",
    "print('Sample of X%s' % ('_'*50))\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CksyxjCnbf5i"
   },
   "outputs": [],
   "source": [
    "# Visualise the data points\n",
    "sns.___ # which method 'plots' all the features in 'pairs'? Hint: Check the Seaborn library.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tI_H3oz0bf5m"
   },
   "source": [
    "### Question: What are other important things to know about the data? Comment on:\n",
    "- Types\n",
    "- Availability\n",
    "- Dispersion and Distribution\n",
    "\n",
    "### Question: Which features could/should be used to cluster the data points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new centroids randomly for all the K clusters including all dimensions\n",
    "def create_centroids(K, features):\n",
    "    \n",
    "    centroids = [] # start with No centroids\n",
    "    \n",
    "    for i in range(K): # need one centroid for each cluster\n",
    "        \n",
    "        dimensions = [] # it can be multi-dimensional\n",
    "        for f in features:\n",
    "            # create a random number between the minimum and maximum of each feature\n",
    "            x = ___ # \n",
    "            dimensions.append(x)\n",
    "        \n",
    "        centroids.append(dimensions) # add all dimensions for the centroids of each cluster\n",
    "\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = create_centroids(3, ['Sepal_Length', 'Petal_Length'])\n",
    "print(\"Random centroids: {}\".format(centroids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vw6PpAqFbf5o"
   },
   "source": [
    "The **Euclidean distance** between points `p` and `q` is the length of the line segment connecting them ($\\overline{pq}$).\n",
    "\n",
    "In **Cartesian coordinates**, if $p = (p_1, p_2,..., p_n)$ and $q = (q_1, q_2,..., q_n)$ are two points in **Euclidean n-space**, then the distance `d` from `p` to `q`, or from `q` to `p` is given by the **Pythagorean formula**:\n",
    "\n",
    "$$\n",
    "{\\displaystyle {\\begin{aligned}d(\\mathbf {p} ,\\mathbf {q} )=d(\\mathbf {q} ,\\mathbf {p} )&={\\sqrt {(q_{1}-p_{1})^{2}+(q_{2}-p_{2})^{2}+\\cdots +(q_{n}-p_{n})^{2}}}\\\\[8pt]&={\\sqrt {\\sum _{i=1}^{n}(q_{i}-p_{i})^{2}}}.\\end{aligned}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ow0NIP-Bbf5p"
   },
   "outputs": [],
   "source": [
    "# Identify the closest centroid for a given data point\n",
    "def closest_centroid(x, centroids):\n",
    "    distances = []\n",
    "    # convert x to a numpy.array; x contains all the features of a data point\n",
    "    p = np.array(x)\n",
    "    for c in centroids:\n",
    "        # convert c to a numpy.array; c contains the coordinates for all the features\n",
    "        q = np.array(c)\n",
    "        # calculate the Euclidean distance between data point `x` and centroid `c`\n",
    "        d = ___ # Hint: consider that the data has been converted to NumPy Arrays\n",
    "        # add the distance for each centroid\n",
    "        distances.append(d)\n",
    "\n",
    "    # return the position (cluster) which has the smallest distance\n",
    "    return np.array(distances).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iOi2rmQgbf5r"
   },
   "outputs": [],
   "source": [
    "# recalculate all the centroids based on the mean of the members of each cluster\n",
    "def update_centroid(X, y, centroids):\n",
    "    c = []\n",
    "    for i in range(len(centroids)): # for each of the existing centroids\n",
    "        \n",
    "        # check if any object was assigned to a cluster\n",
    "        if X[y == i].shape[0]:\n",
    "            dimensions = []\n",
    "            for f in X.columns: # for all the features\n",
    "                x = ___ # calculate the mean\n",
    "                dimensions.append(x)\n",
    "            c.append(dimensions)\n",
    "        \n",
    "        else: # if a cluster got no members\n",
    "            c.append(___) # keep the previous coordinates\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opMhliW1bf5t"
   },
   "outputs": [],
   "source": [
    "# plot a chart of the data points and centroids either generic or identifying the clusters\n",
    "# NOTE: for visualisation purposes, only consider the first two features\n",
    "def plot_data(ax, X, y, centroids, title, show_clusters=False):\n",
    "    \n",
    "    # unpack the coordinates of the centroids\n",
    "    a = [z[0] for z in centroids]\n",
    "    b = [z[1] for z in centroids]\n",
    "\n",
    "    # show distinct colours if asked to identify the clusters\n",
    "    if show_clusters:\n",
    "        colours = 'rgbykcm'\n",
    "        for i in range(len(centroids)):\n",
    "            ax.scatter(X[features[0]][y == i], X[features[1]][y == i], c = colours[i], label = 'Cluster %d' % i)\n",
    "    # show data points without cluster identification\n",
    "    else:\n",
    "        ax.scatter(X[features[0]], X[features[1]], label = 'Data Point')\n",
    "        \n",
    "    # label\n",
    "    ax.set_xlabel(features[0])\n",
    "    ax.set_ylabel(features[1])\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # identify the centroids\n",
    "    ax.scatter(a, b, c = 'k', linewidths = 5, marker = 'x', label = 'Centroid')\n",
    "    for i in range(len(a)):\n",
    "        c = colours[i] if show_clusters else 'k'\n",
    "        ax.axvline(x = a[i], color = c, linestyle = '--', linewidth = 1)\n",
    "        ax.axhline(y = b[i], color = c, linestyle = '--', linewidth = 1)\n",
    "\n",
    "    # create a text to show the centroids' coordinates\n",
    "    t = '\\n'.join(['%d: (%.3f, %.3f)' % (i, a, b) for (i, (a, b)) in enumerate(centroids)])\n",
    "    ax.text(7.2, 1, t)\n",
    "\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8CWofS2bf5u",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## K_Means\n",
    "## Note that the comments match the outlined K-Means Algorithm in the presentation\n",
    "\n",
    "# For debugging\n",
    "step = 0\n",
    "show_steps = True\n",
    "\n",
    "# 1. Define the number of clusters `K`\n",
    "K = 3\n",
    "\n",
    "# list the features to be used\n",
    "features = ['Sepal_Length', 'Petal_Length']\n",
    "\n",
    "# 2. Select `K` cluster centres randomly\n",
    "centroids = ___ # Create the initial centroids\n",
    "print(\"Initial centroids: \\n{}\".format('\\n'.join(['(%.2f, %.2f)' % (c[0], c[1]) for c in centroids])))\n",
    "\n",
    "# plot the data points and initial centroids (the 'Before')\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (18, 8))\n",
    "plot_data(axes[0], X[features], None, centroids, title=\"Initial\")\n",
    "\n",
    "# repeat until makes no moves\n",
    "while True:\n",
    "    # 3. Calculate the distance between each data point and cluster centres\n",
    "    # 4. Assign the data point to the cluster whose distance from its centre is minimum\n",
    "    y = ___ # this can be a bit hardcore, think about it for a while\n",
    "            # Hints: the `apply()` method with a `lambda` function and returning some value\n",
    "            # Note: `for` loops are acceptable but slow\n",
    "    \n",
    "    # move the known assignment be the previous state, for post comparison\n",
    "    old_c = centroids.copy()\n",
    "    \n",
    "    # 5. Recalculate all new cluster centres by averaging the objects of each cluster\n",
    "    centroids = ___ # Update the centroids\n",
    "    \n",
    "    # 6. Repeat steps 3 to 5 until the centroids do not change\n",
    "    if old_c == centroids:\n",
    "        break\n",
    "        \n",
    "    # 7. For debugging\n",
    "    if show_steps:\n",
    "        print(\"Step {}\".format(step))\n",
    "        print('\\n'.join(['(%.2f, %.2f)' % (c[0], c[1]) for c in centroids]))\n",
    "    step += 1\n",
    "    \n",
    "# plot the data points identified by cluster and final centroids (the 'After')\n",
    "plot_data(axes[1], X[features], y, centroids, title=\"Final\", show_clusters=True)\n",
    "plt.show()\n",
    "print(\"Final centroids: \\n{}\".format('\\n'.join(['(%.2f, %.2f)' % (c[0], c[1]) for c in centroids])))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab-6_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
