{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IOD_Lab 4.2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"7dsAxdi0XF5U"},"source":["<div>\n","<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"UWARFzbRXF5b"},"source":["# Lab 4.2: Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"gpNkmk2YXF5d"},"source":["## Load & Explore Data"]},{"cell_type":"code","metadata":{"id":"J0BM6vo-XF5f"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FACR8kagXF5p"},"source":["## Load Data"]},{"cell_type":"code","metadata":{"id":"SmCNaDCfXF5q"},"source":["# Read CSV\n","wine_csv = 'winequality_merged.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"scteyINnXF5s"},"source":["## Explore Data (Exploratory Data Analysis)"]},{"cell_type":"code","metadata":{"id":"u-Q3RTtuXF5t"},"source":["# ANSWER"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_xtHG5jGXF5v"},"source":["## Set Target Variable"]},{"cell_type":"markdown","metadata":{"id":"qkLJQxkSXF5y"},"source":["Create a target variable for wine quality."]},{"cell_type":"code","metadata":{"id":"oaxrah6uXF51"},"source":["# Target Variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_tBqj2sqXF55"},"source":["# Set Predictor Variables based on correlation"]},{"cell_type":"markdown","metadata":{"id":"lY5kp1kzXF56"},"source":["Create a predictor matrix with variables of your choice. State your reason."]},{"cell_type":"code","metadata":{"id":"E0DcG8vaXF56"},"source":["# ANSWER"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sUssbQORXF59"},"source":["# Using Linear Regression model\n","\n","Reference: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression"]},{"cell_type":"code","metadata":{"id":"YVrOXac4XF59"},"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PHMTdm2BXF6A"},"source":["# Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BgSMd_xaXF6F"},"source":["# Create a model for Linear Regression\n","\n","# Fit the model with the Training data\n","\n","# Calculate the score (R^2 for Regression) for Training Data\n","\n","# Calculate the score (R^2 for Regression) for Testing Data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7BoIOIHDYD0r"},"source":["# Forward Feature Selection\n","\n","> Forward Selection: Forward selection is an iterative method in which we start with having no feature in the model. In each iteration, we keep adding the feature which best improves our model till an addition of a new variable does not improve the performance of the model.\n","\n","Create a Regression model using Forward Feature Selection by looping over all the features adding one at a time until there are no improvements on the prediction metric ( R2  and  AdjustedR2  in this case)."]},{"cell_type":"markdown","metadata":{"id":"sF-ugXF_YD0r"},"source":["### Overview of the code below\n","\n","The external `while` loop goes forever until there are no improvements to the model, which is controlled by the flag `changed` (until is **not** changed).\n","The inner `for` loop goes over each of the features not yet included in the model and calculates the correlation coefficient. If any model improves on the previous best model then the records are updated.\n","\n","### Code variables\n","- `included`: list of the features (predictors) that were included in the model; starts empty.\n","- `excluded`: list of features that have **not** been included in the model; starts as the full list of features.\n","- `best`: dictionary to keep record of the best model found at any stage; starts 'empty'.\n","- `model`: object of class LinearRegression, with default values for all parameters.\n","\n","### Adjusted $R^2$ formula\n","$$Adjusted \\; R^2 = 1 - { (1 - R^2) (n - 1)  \\over n - k - 1 }$$"]},{"cell_type":"code","metadata":{"id":"ba3mMRUcYD0r"},"source":["## Flag intermediate output\n","show_steps = True   # for testing/debugging"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qqdqEo0YYD0s"},"source":["## Use Forward Feature Selection to pick a good model\n","\n","# start with no predictors\n","included = []\n","# keep track of model and parameters\n","best = {'feature': '', 'r2': 0, 'a_r2': 0}\n","# create a model object to hold the modelling parameters\n","model = LinearRegression() # create a model for Linear Regression\n","# get the number of cases in the test data\n","n = X_test.shape[0]\n","\n","while True:\n","    changed = False\n","    \n","    if show_steps:\n","        print('') \n","\n","    # list the features to be evaluated\n","    excluded = list(set(X.columns) - set(included))\n","    \n","    if show_steps:\n","        print('(Step) Excluded = %s' % ', '.join(excluded))  \n","\n","    # for each remaining feature to be evaluated\n","    for new_column in excluded:\n","        \n","        if show_steps:\n","            print('(Step) Trying %s...' % new_column)\n","            print('(Step) - Features = %s' % ', '.join(included + [new_column]))\n","\n","        # fit the model with the Training data\n","        fit = ___ # fit a model; consider which predictors should be included\n","        # calculate the score (R^2 for Regression)\n","        r2 = ___ # calculate the score\n","        # number of predictors in this model\n","        k = len(included) + 1\n","        # calculate the adjusted R^2\n","        adjusted_r2 = ___ # calculate the Adjusted R^2\n","\n","        if show_steps:\n","            print('(Step) - Adjusted R^2: This = %.3f; Best = %.3f' % \n","                  (adjusted_r2, best['a_r2']))\n","\n","        # if model improves\n","        if adjusted_r2 > best['a_r2']:\n","            # record new parameters\n","            best = {'feature': new_column, 'r2': r2, 'a_r2': adjusted_r2}\n","            # flag that found a better model\n","            changed = True\n","            if show_steps:\n","                print('(Step) - New Best!   : Feature = %s; R^2 = %.3f; Adjusted R^2 = %.3f' % \n","                      (best['feature'], best['r2'], best['a_r2']))\n","    # END for\n","\n","    # if found a better model after testing all remaining features\n","    if changed:\n","        # update control details\n","        included.append(best['feature'])\n","        excluded = list(set(excluded) - set(best['feature']))\n","        print('Added feature %-4s with R^2 = %.3f and adjusted R^2 = %.3f' % \n","              (best['feature'], best['r2'], best['a_r2']))\n","    else:\n","        # terminate if no better model\n","        break\n","\n","print('')\n","print('Resulting features:')\n","print(', '.join(included))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VyFE_4hiYD0s"},"source":["# Cross validation"]},{"cell_type":"code","metadata":{"id":"SWiEaV77YD0t"},"source":["# Answer"],"execution_count":null,"outputs":[]}]}